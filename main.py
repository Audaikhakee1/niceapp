import os
import asyncio
import random
import uvicorn
import httpx  # Ø³Ù†Ø³ØªØ®Ø¯Ù… Ù‡Ø°Ø§ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ù…ÙƒØªØ¨Ø© Ø¬ÙˆØ¬Ù„ Ø§Ù„Ù…Ø¹Ø·Ù„Ø©
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes

app = FastAPI()
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

# --- Ø§Ù„Ù…ÙØ§ØªÙŠØ­ ---
TELEGRAM_TOKEN = "8123154181:AAEZinaf1XcMDyuXgebGJeC0NoHsw-a7yIs"
GEMINI_API_KEY = "AIzaSyA9OpSJAz2nE7dBc7DylYz6_LHId-u28ck"

async def get_ai_response_direct(prompt):
    # Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ø¥Ù„Ù‰ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…Ø³ØªÙ‚Ø±Ø© v1 Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† v1beta
    # ÙˆØ§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø³Ù…Ù‰ Ø§Ù„ÙƒØ§Ù…Ù„ Ø§Ù„Ø±Ø³Ù…ÙŠ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
    url = f"https://generativelanguage.googleapis.com/v1/models/gemini-1.5-flash:generateContent?key={GEMINI_API_KEY}"
    
    payload = {
        "contents": [{"parts": [{"text": prompt}]}]
    }
    
    async with httpx.AsyncClient() as client:
        try:
            response = await client.post(url, json=payload, timeout=30.0)
            result = response.json()
            
            # ÙØ­Øµ Ø§Ù„Ø±Ø¯ ÙˆØªÙˆØ¬ÙŠÙ‡Ù‡
            if 'candidates' in result:
                return result['candidates'][0]['content']['parts'][0]['text']
            elif 'error' in result:
                return f"âš ï¸ ØªÙ†Ø¨ÙŠÙ‡ Ù…Ù† Ø¬ÙˆØ¬Ù„: {result['error']['message']}"
            else:
                return "ğŸ”„ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ø³ØªÙ„Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙ„ÙƒÙ† Ø§Ù„Ø±Ø¯ ØºØ§Ù…Ø¶. Ø­Ø§ÙˆÙ„ Ø«Ø§Ù†ÙŠØ©."
        except Exception as e:
            return f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: {str(e)}"
bot_running = False
application = None

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message or not update.message.text: return
    user_text = update.message.text
    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action="typing")

    # Ø¬Ù„Ø¨ Ø§Ù„Ø±Ø¯ Ø¹Ø¨Ø± Ø§Ù„Ø§ØªØµØ§Ù„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
    answer = await get_ai_response_direct(user_text)
    await update.message.reply_text(answer)

@app.get("/stats")
async def get_stats():
    return {"cpu": random.randint(10, 50), "ram": random.randint(20, 40)}

@app.get("/bot/toggle")
async def toggle_bot():
    global application, bot_running
    if not bot_running:
        application = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
        application.add_handler(CommandHandler("start", lambda u, c: u.message.reply_text("Ø§Ù„ÙˆØ­Ø´ Ø§Ø³ØªÙŠÙ‚Ø¸ Ø¨Ù†Ø¸Ø§Ù… Ø§Ù„Ø§ØªØµØ§Ù„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±!")))
        application.add_handler(MessageHandler(filters.TEXT & (~filters.COMMAND), handle_message))
        await application.initialize()
        await application.start()
        await application.updater.start_polling()
        bot_running = True
        return {"status": "Running"}
    return {"status": "Active"}

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)

