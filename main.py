import os
import asyncio
import random
import uvicorn
import google.generativeai as genai
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes

app = FastAPI()
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

# --- Ø§Ù„Ù…ÙØ§ØªÙŠØ­ (ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­ØªÙ‡Ø§ ØªÙ…Ø§Ù…Ø§Ù‹) ---
TELEGRAM_TOKEN = "8123154181:AAEZinaf1XcMDyuXgebGJeC0NoHsw-a7yIs"
GEMINI_API_KEY = "AIzaSyA9OpSJAz2nE7dBc7DylYz6_LHId-u28ck"

# Ù…Ø­Ø§ÙˆÙ„Ø© ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø£ÙƒØ«Ø± Ù…Ù† Ù†Ø³Ø®Ø© Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ù†Ø¬Ø§Ø­
genai.configure(api_key=GEMINI_API_KEY)

def get_ai_response(prompt):
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø³Ù…Ù‰ Ø§Ù„Ø®Ø§Ù… Ø§Ù„Ø£Ø­Ø¯Ø« Ø§Ù„Ø°ÙŠ ÙŠØ¯Ø¹Ù… ÙƒØ§ÙØ© Ø§Ù„Ù†Ø³Ø®
    model = genai.GenerativeModel('models/gemini-1.5-flash-latest') 
    response = model.generate_content(prompt)
    return response.text

chats_memory = {}
bot_running = False
application = None

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message or not update.message.text: return
    user_text = update.message.text
    
    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action="typing")

    try:
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø±Ø¯
        response_text = get_ai_response(user_text)
        await update.message.reply_text(response_text)
        
    except Exception as e:
        full_error = str(e)
        print(f"DEBUG ERROR: {full_error}")
        
        # Ø¥Ø°Ø§ Ø§Ø³ØªÙ…Ø± Ø§Ù„Ø®Ø·Ø£ØŒ Ø³Ù†Ø±Ø³Ù„ Ù„Ùƒ "ÙƒÙˆØ¯ Ø§Ù„Ø¹Ø·Ù„" Ù„ØªØ¹Ø·ÙŠÙ‡ Ù„Ù†Ø§
        if "403" in full_error:
            msg = "ğŸš« Ø®Ø·Ø£ 403: Ø¬ÙˆØ¬Ù„ ØªØ±ÙØ¶ Ø§Ù„ØªÙˆÙƒÙ† Ø£Ùˆ Ø§Ù„Ù…ÙˆÙ‚Ø¹. ØªØ£ÙƒØ¯ Ù…Ù† ØªÙØ¹ÙŠÙ„ Gemini ÙÙŠ AI Studio."
        elif "429" in full_error:
            msg = "â³ Ø®Ø·Ø£ 429: Ø­ØµØ© Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠØ© Ø§Ù†ØªÙ‡Øª Ù…Ø¤Ù‚ØªØ§Ù‹."
        else:
            msg = f"ğŸ” ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø¹Ø·Ù„ Ø§Ù„ØªÙ‚Ù†ÙŠ: {full_error[:100]}" # ÙŠØ±Ø³Ù„ Ø£ÙˆÙ„ 100 Ø­Ø±Ù Ù…Ù† Ø§Ù„Ø®Ø·Ø£
            
        await update.message.reply_text(msg)

@app.get("/stats")
async def get_stats():
    return {"cpu": random.randint(10, 50), "ram": random.randint(20, 40)}

@app.get("/bot/toggle")
async def toggle_bot():
    global application, bot_running
    if not bot_running:
        application = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
        application.add_handler(CommandHandler("start", lambda u, c: u.message.reply_text("Ø§Ù„ÙˆØ­Ø´ Ø§Ø³ØªÙŠÙ‚Ø¸! Ø¬Ø±Ø¨ Ù…Ø­Ø§Ø¯Ø«ØªÙŠ Ø§Ù„Ø¢Ù†.")))
        application.add_handler(MessageHandler(filters.TEXT & (~filters.COMMAND), handle_message))
        await application.initialize()
        await application.start()
        await application.updater.start_polling()
        bot_running = True
        return {"status": "Running"}
    return {"status": "Active"}

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)


